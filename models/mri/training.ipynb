{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-06T04:51:00.255475Z",
     "start_time": "2025-04-06T04:50:54.516943Z"
    }
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, applications\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T04:51:00.293474Z",
     "start_time": "2025-04-06T04:51:00.288532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ],
   "id": "924c48dfb49028a4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T04:51:04.189727Z",
     "start_time": "2025-04-06T04:51:04.186340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parameters\n",
    "IMG_SIZE = (224, 224)  # Standard size for many pre-trained models\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20\n",
    "LEARNING_RATE = 0.0001"
   ],
   "id": "20fb9807f38b492f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T04:51:23.047633Z",
     "start_time": "2025-04-06T04:51:23.033356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. Data Preparation and Augmentation\n",
    "def create_data_generators(data_dir, batch_size=BATCH_SIZE):\n",
    "    \"\"\"\n",
    "    Create train, validation and test data generators.\n",
    "    Assumes data_dir has two subdirectories: 'brain_mri' and 'other_scans'\n",
    "    \"\"\"\n",
    "    # Data augmentation for training\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        rotation_range=15,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.15  # 15% for validation\n",
    "    )\n",
    "\n",
    "    # Just rescaling for testing\n",
    "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # Load and split the data\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        subset='training'\n",
    "    )\n",
    "\n",
    "    valid_generator = train_datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=IMG_SIZE,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        subset='validation'\n",
    "    )\n",
    "\n",
    "    # Optionally create a separate test set\n",
    "    # For this example, we'll use the validation set for testing\n",
    "\n",
    "    return train_generator, valid_generator"
   ],
   "id": "510611caeeb04bd2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T04:51:36.584656Z",
     "start_time": "2025-04-06T04:51:36.580519Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Create Model (Transfer Learning with Fine-tuning)\n",
    "def create_model():\n",
    "    \"\"\"Create a transfer learning model based on ResNet50\"\"\"\n",
    "    # Load pre-trained model without top layers\n",
    "    base_model = applications.ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)\n",
    "    )\n",
    "\n",
    "    # Freeze the base model\n",
    "    base_model.trainable = False\n",
    "\n",
    "    # Add custom classification head\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(1, activation='sigmoid')  # Binary classification\n",
    "    ])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ],
   "id": "13b48406737d0197",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T04:51:49.927737Z",
     "start_time": "2025-04-06T04:51:49.910296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Train model with callbacks\n",
    "def train_model(model, train_generator, valid_generator, epochs=EPOCHS):\n",
    "    # Add callbacks for better training\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'best_brain_mri_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max'\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=3\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=valid_generator,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    return history, model\n",
    "\n"
   ],
   "id": "5060563c2c3f74bc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T04:52:14.509951Z",
     "start_time": "2025-04-06T04:52:14.504225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. After initial training, fine-tune the model\n",
    "def fine_tune_model(model, train_generator, valid_generator, epochs=10):\n",
    "    # Unfreeze some of the layers in the base model\n",
    "    base_model = model.layers[0]\n",
    "    # Unfreeze the last 30 layers\n",
    "    for layer in base_model.layers[-30:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    # Recompile with a lower learning rate\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE / 10),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "    )\n",
    "\n",
    "    # Continue training\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            'best_fine_tuned_brain_mri_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max'\n",
    "        ),\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=5,\n",
    "            restore_best_weights=True\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        epochs=epochs,\n",
    "        validation_data=valid_generator,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "    model.save('mode.h5')  # Save the fine-tuned model\n",
    "\n",
    "    return history, model\n"
   ],
   "id": "db504b99ae29e87c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T04:52:15.974230Z",
     "start_time": "2025-04-06T04:52:15.970904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Evaluation and visualization\n",
    "def evaluate_model(model, test_generator):\n",
    "    # Evaluate the model\n",
    "    results = model.evaluate(test_generator)\n",
    "    print(f\"Test Loss: {results[0]:.4f}\")\n",
    "    print(f\"Test Accuracy: {results[1]:.4f}\")\n",
    "    print(f\"Test AUC: {results[2]:.4f}\")\n",
    "    print(f\"Test Precision: {results[3]:.4f}\")\n",
    "    print(f\"Test Recall: {results[4]:.4f}\")\n",
    "\n",
    "    # Get predictions for confusion matrix\n",
    "    test_generator.reset()\n",
    "    y_pred = model.predict(test_generator)\n",
    "    y_pred_classes = (y_pred > 0.5).astype(int)\n",
    "\n",
    "    return y_pred_classes\n"
   ],
   "id": "edb6c7ec838682ff",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-06T04:52:27.186751Z",
     "start_time": "2025-04-06T04:52:27.182493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# 6. Visualize training history\n",
    "def plot_training_history(history):\n",
    "    # Plot accuracy and loss curves\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Accuracy plot\n",
    "    ax1.plot(history.history['accuracy'])\n",
    "    ax1.plot(history.history['val_accuracy'])\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend(['Train', 'Validation'], loc='lower right')\n",
    "\n",
    "    # Loss plot\n",
    "    ax2.plot(history.history['loss'])\n",
    "    ax2.plot(history.history['val_loss'])\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend(['Train', 'Validation'], loc='upper right')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_history.png')\n",
    "    plt.show()\n"
   ],
   "id": "897aef8a7c82ff38",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Main execution function\n",
    "def main(data_dir):\n",
    "    # Create data generators\n",
    "    train_generator, valid_generator = create_data_generators(data_dir)\n",
    "\n",
    "    # Create and train initial model\n",
    "    model = create_model()\n",
    "    print(\"Model created. Starting initial training...\")\n",
    "\n",
    "    history, model = train_model(model, train_generator, valid_generator)\n",
    "    print(\"Initial training completed. Starting fine-tuning...\")\n",
    "\n",
    "    # Fine-tune model\n",
    "    fine_tune_history, model = fine_tune_model(model, train_generator, valid_generator)\n",
    "    print(\"Fine-tuning completed. Evaluating model...\")\n",
    "\n",
    "    # Evaluate model\n",
    "    y_pred_classes = evaluate_model(model, valid_generator)\n",
    "\n",
    "    # Plot training history\n",
    "    plot_training_history(fine_tune_history)\n",
    "\n",
    "    # Save the final model\n",
    "    model.save('final_brain_mri_classifier_model.h5')\n",
    "    print(\"Model saved as 'final_brain_mri_classifier_model.h5'\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Example usage (commented out - replace with your data directory)\n",
    "if __name__ == \"__main__\":\n",
    "    data_dir = \"../../data/mri/\"  # Should have subfolders \"brain_mri\" and \"other_scans\"\n",
    "    main(data_dir)"
   ],
   "id": "5a65a8c16e11bbfa"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
